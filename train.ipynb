{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "mount_file_id": "https://github.com/PanoEvJ/Constitutional_BloomZ/blob/main/train.ipynb",
      "authorship_tag": "ABX9TyP8cqf7du9aZdkn5WcxeogX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PanoEvJ/Constitutional_BloomZ/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install trl"
      ],
      "metadata": {
        "id": "bHR5U_q6cYG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "0H5DMYG2do49",
        "outputId": "1f8083e0-0783-40f0-d87e-7c309057e494",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp '/content/gdrive/MyDrive/train.py' ."
      ],
      "metadata": {
        "id": "hpu5Yf1qsoTt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp train.py '/content/gdrive/MyDrive/'"
      ],
      "metadata": {
        "id": "qiuRNcHfeedL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --model_save_path='./'"
      ],
      "metadata": {
        "id": "7lTntHRwecyr",
        "outputId": "72410cdd-cad3-47d7-b12b-20fd00b1e8ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-30 22:16:52.422446: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Found cached dataset json (/root/.cache/huggingface/datasets/allenai___json/allenai--real-toxicity-prompts-eb8779dd2693db47/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/allenai___json/allenai--real-toxicity-prompts-eb8779dd2693db47/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-5412c1ea41b44466.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/allenai___json/allenai--real-toxicity-prompts-eb8779dd2693db47/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-6fcd12cb5801f5e0.arrow\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:197: UserWarning: num_shared_layers is ignored when ref_model is provided. Two different models are used for the model and the reference model and no layers are shared.\n",
            "  warnings.warn(\n",
            "0it [00:00, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "0it [00:27, ?it/s]\n",
            "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/\u001b[0m\u001b[1;33mtrain.py\u001b[0m:\u001b[94m235\u001b[0m in \u001b[92m<module>\u001b[0m                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m232 \u001b[0m\u001b[2m│   \u001b[0mrewards = [torch.tensor(output) \u001b[94mfor\u001b[0m output \u001b[95min\u001b[0m toxicity_labels]     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m233 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m234 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Run PPO step\u001b[0m                                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m235 \u001b[2m│   \u001b[0mstats = ppo_trainer.step(query_tensors, response_tensors, rewards) \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m236 \u001b[0m\u001b[2m│   \u001b[0mppo_trainer.log_stats(stats, batch, rewards)                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m237 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m238 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Save model every 100 epochs\u001b[0m                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/lib/python3.10/\u001b[0m\u001b[1;33mcontextlib.py\u001b[0m:\u001b[94m79\u001b[0m in \u001b[92minner\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 76 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[1;95m@wraps\u001b[0m(func)                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 77 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92minner\u001b[0m(*args, **kwds):                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 78 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m._recreate_cm():                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 79 \u001b[2m│   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwds)                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 80 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m inner                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 81 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 82 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/trl/trainer/\u001b[0m\u001b[1;33mppo_trainer.py\u001b[0m:\u001b[94m541\u001b[0m in    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mstep\u001b[0m                                                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 538 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.model, batch[\u001b[33m\"\u001b[0m\u001b[33mqueries\u001b[0m\u001b[33m\"\u001b[0m], batch[\u001b[33m\"\u001b[0m\u001b[33mresponse\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 539 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m)                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 540 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 541 \u001b[2m│   │   │   │   \u001b[0mtrain_stats = \u001b[96mself\u001b[0m.train_minibatch(                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 542 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mbatch[\u001b[33m\"\u001b[0m\u001b[33mlogprobs\u001b[0m\u001b[33m\"\u001b[0m],                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 543 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mbatch[\u001b[33m\"\u001b[0m\u001b[33mvalues\u001b[0m\u001b[33m\"\u001b[0m],                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 544 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mbatch[\u001b[33m\"\u001b[0m\u001b[33mrewards\u001b[0m\u001b[33m\"\u001b[0m],                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/lib/python3.10/\u001b[0m\u001b[1;33mcontextlib.py\u001b[0m:\u001b[94m79\u001b[0m in \u001b[92minner\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 76 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[1;95m@wraps\u001b[0m(func)                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 77 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92minner\u001b[0m(*args, **kwds):                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 78 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m._recreate_cm():                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 79 \u001b[2m│   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwds)                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 80 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m inner                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 81 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 82 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/trl/trainer/\u001b[0m\u001b[1;33mppo_trainer.py\u001b[0m:\u001b[94m760\u001b[0m in    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mtrain_minibatch\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 757 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 758 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 759 \u001b[0m\u001b[2m│   │   \u001b[0mt = time.time()                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 760 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.optimizer.step()                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 761 \u001b[0m\u001b[2m│   │   \u001b[0mtrain_stats[\u001b[33m\"\u001b[0m\u001b[33mtime/ppo/optimizer_step\u001b[0m\u001b[33m\"\u001b[0m] = torch.Tensor([time.t \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 762 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m train_stats                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 763 \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/accelerate/\u001b[0m\u001b[1;33moptimizer.py\u001b[0m:\u001b[94m140\u001b[0m in \u001b[92mstep\u001b[0m  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m137 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# If we reduced the loss scale, it means the optimizer\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m138 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._is_overflow = scale_after < scale_before         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m139 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m140 \u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.optimizer.step(closure)                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m141 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m142 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_switch_parameters\u001b[0m(\u001b[96mself\u001b[0m, parameters_map):                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m143 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m param_group \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.optimizer.param_groups:                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/optim/\u001b[0m\u001b[1;33moptimizer.py\u001b[0m:\u001b[94m280\u001b[0m in      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mwrapper\u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m277 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mRuntimeError\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m{\u001b[0mfunc\u001b[33m}\u001b[0m\u001b[33m must return No\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m278 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │   │      \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mbut got \u001b[0m\u001b[33m{\u001b[0mresult\u001b[33m}\u001b[0m\u001b[33m.\u001b[0m\u001b[33m\"\u001b[0m)   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m279 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m280 \u001b[2m│   │   │   │   \u001b[0mout = func(*args, **kwargs)                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m281 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._optimizer_step_code()                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m282 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m283 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# call optimizer step post hooks\u001b[0m                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/optim/\u001b[0m\u001b[1;33moptimizer.py\u001b[0m:\u001b[94m33\u001b[0m in       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92m_use_grad\u001b[0m                                                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 30 \u001b[0m\u001b[2m│   │   \u001b[0mprev_grad = torch.is_grad_enabled()                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 31 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 32 \u001b[0m\u001b[2m│   │   │   \u001b[0mtorch.set_grad_enabled(\u001b[96mself\u001b[0m.defaults[\u001b[33m'\u001b[0m\u001b[33mdifferentiable\u001b[0m\u001b[33m'\u001b[0m])    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 33 \u001b[2m│   │   │   \u001b[0mret = func(\u001b[96mself\u001b[0m, *args, **kwargs)                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 34 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfinally\u001b[0m:                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 35 \u001b[0m\u001b[2m│   │   │   \u001b[0mtorch.set_grad_enabled(prev_grad)                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 36 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m ret                                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/optim/\u001b[0m\u001b[1;33madam.py\u001b[0m:\u001b[94m141\u001b[0m in \u001b[92mstep\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m138 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mmax_exp_avg_sqs,                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m139 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mstate_steps)                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m140 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m141 \u001b[2m│   │   │   \u001b[0madam(                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m142 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mparams_with_grad,                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m143 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mgrads,                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m144 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mexp_avgs,                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/optim/\u001b[0m\u001b[1;33madam.py\u001b[0m:\u001b[94m281\u001b[0m in \u001b[92madam\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m278 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melse\u001b[0m:                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m279 \u001b[0m\u001b[2m│   │   \u001b[0mfunc = _single_tensor_adam                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m280 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m281 \u001b[2m│   \u001b[0mfunc(params,                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m282 \u001b[0m\u001b[2m│   │    \u001b[0mgrads,                                                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m283 \u001b[0m\u001b[2m│   │    \u001b[0mexp_avgs,                                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m284 \u001b[0m\u001b[2m│   │    \u001b[0mexp_avg_sqs,                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/optim/\u001b[0m\u001b[1;33madam.py\u001b[0m:\u001b[94m507\u001b[0m in           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92m_multi_tensor_adam\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m504 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m505 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mexp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_s \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m506 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mtorch._foreach_div_(exp_avg_sq_sqrt, bias_correction2_ \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m507 \u001b[2m│   │   │   │   \u001b[0mdenom = torch._foreach_add(exp_avg_sq_sqrt, eps)       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m508 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m509 \u001b[0m\u001b[2m│   │   │   \u001b[0mtorch._foreach_addcdiv_(params_, device_exp_avgs, denom, s \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m510 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\u001b[1;91mOutOfMemoryError: \u001b[0mCUDA out of memory. Tried to allocate \u001b[1;36m128.00\u001b[0m MiB \u001b[1m(\u001b[0mGPU \u001b[1;36m0\u001b[0m; \u001b[1;36m39.56\u001b[0m\n",
            "GiB total capacity; \u001b[1;36m37.65\u001b[0m GiB already allocated; \u001b[1;36m126.56\u001b[0m MiB free; \u001b[1;36m37.84\u001b[0m GiB \n",
            "reserved in total by PyTorch\u001b[1m)\u001b[0m If reserved memory is >> allocated memory try \n",
            "setting max_split_size_mb to avoid fragmentation.  See documentation for Memory \n",
            "Management and PYTORCH_CUDA_ALLOC_CONF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C38fen5Ne34l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}